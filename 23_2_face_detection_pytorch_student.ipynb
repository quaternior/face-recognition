{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a_5yIAd90EW9"
   },
   "source": [
    "## **Do NOT touch this cell**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "R9-wUawtssbU"
   },
   "outputs": [],
   "source": [
    "# !wget http://crowley-coutaz.fr/HeadPoseDataSet/HeadPoseImageDatabase.tar.gz\n",
    "# !tar -xvzf HeadPoseImageDatabase.tar.gz\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import torch.utils as utils\n",
    "import random\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "person_list = sorted(glob.glob('Person*')) # search the folders starting with 'Person'\n",
    "\n",
    "img_list = []\n",
    "train_img_list = []\n",
    "val_img_list = []\n",
    "test_img_list = []\n",
    "H = 288\n",
    "W = 384\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:q5923in1) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>█▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>Validation loss</td><td>▆▆▇█▆▆▆▇▂▁▁▂▃▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Training loss</td><td>0.00781</td></tr><tr><td>Validation loss</td><td>0.00241</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">atomic-salad-2</strong> at: <a href='https://wandb.ai/daunman00/Face%20Detection/runs/q5923in1' target=\"_blank\">https://wandb.ai/daunman00/Face%20Detection/runs/q5923in1</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231208_075833-q5923in1/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:q5923in1). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/wandb/run-20231208_080009-0mkcaolx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/daunman00/Face%20Detection/runs/0mkcaolx' target=\"_blank\">glad-bush-3</a></strong> to <a href='https://wandb.ai/daunman00/Face%20Detection' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/daunman00/Face%20Detection' target=\"_blank\">https://wandb.ai/daunman00/Face%20Detection</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/daunman00/Face%20Detection/runs/0mkcaolx' target=\"_blank\">https://wandb.ai/daunman00/Face%20Detection/runs/0mkcaolx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "learning_rate = 1e-5\n",
    "epochs=200\n",
    "wandb.init(project='Face Detection')\n",
    "wandb.run.name = 'VGG16, SmoothL1, AdamW, lr='+str(learning_rate)+', epchs='+str(epochs)\n",
    "wandb.run.save()\n",
    "args = {\n",
    "    \"learning_rate\": learning_rate,\n",
    "    \"epochs\": epochs\n",
    "}\n",
    "wandb.config.update(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o6wGbMN70M0H"
   },
   "source": [
    "## **You can change the list of training and validation persons**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "r7BT6WyxnyOU"
   },
   "outputs": [],
   "source": [
    "# Train & Validation Select\n",
    "train_person = [0,1,2,3,4,5,6,7,8]\n",
    "val_person = [9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Khk_FTO0Pxd"
   },
   "source": [
    "##**Do NOT touch this cell**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "uz-RNpeln-5m"
   },
   "outputs": [],
   "source": [
    "test_person = [10,11,12,13,14]\n",
    "\n",
    "for i in range(len(person_list)):\n",
    "    if i in train_person:\n",
    "        train_img_list.extend(glob.glob(os.path.join(person_list[i], '*.jpg')))\n",
    "    if i in test_person:\n",
    "        test_img_list.extend(glob.glob(os.path.join(person_list[i], '*.jpg')))\n",
    "    if i in val_person:\n",
    "        val_img_list.extend(glob.glob(os.path.join(person_list[i], '*.jpg')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UL0PuF3_0RfV"
   },
   "source": [
    "## **You can change Transform.Compose (Data Augmentation)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "wAGtgKsAorwG"
   },
   "outputs": [],
   "source": [
    "# Transformation with data augmentation\n",
    "image_train_transform = transforms.Compose([\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize((0.5612, 0.5684, 0.5908),(0.2566,0.2496, 0.2446)),\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yac6iWXGkaCz"
   },
   "source": [
    "## **Do NOT touch this cell**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "Xq3C05ttkaCz"
   },
   "outputs": [],
   "source": [
    "image_test_transform = transforms.Compose([\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize((0.5612, 0.5684, 0.5908),(0.2566,0.2496, 0.2446)),\n",
    "])\n",
    "\n",
    "image_inverse_transform = transforms.Compose([\n",
    "                                              transforms.Normalize((-2.1868,-2.2768,-2.4146),(3.8966,4.0052,4.0869)),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lUoPy1vA0Uev"
   },
   "source": [
    "## **Do NOT touch this cell**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 360
    },
    "id": "ZxwRxnMlyoOL",
    "outputId": "3b1827ec-59c7-4c6c-f591-c3e44c8430f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               ( X,   Y)\n",
      "Top Left     : ( 14,110)\n",
      "Bottom Right : (118,260)\n"
     ]
    }
   ],
   "source": [
    "############################################################################\n",
    "#\n",
    "#                   Data set and dataloader\n",
    "#\n",
    "############################################################################\n",
    "\n",
    "class custom_dataset():\n",
    "    def __init__(self, img_list, is_train):\n",
    "        self.img_list = img_list\n",
    "        self.is_train = is_train\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        img_file = self.img_list[index]\n",
    "\n",
    "        image = cv2.imread(img_file) # read the image file\n",
    "        image = Image.fromarray(image)\n",
    "        txt_file = img_file[:-4] + '.txt' # take the txt file address from the image file address\n",
    "        with open(txt_file,'r') as f:\n",
    "            line = f.read().splitlines()\n",
    "            center_x = int(line[3])/W\n",
    "            center_y = int(line[4])/H\n",
    "            width = int(line[5])/W\n",
    "            height = int(line[6])/H # open the text file and take the face box information from it\n",
    "        if self.is_train:\n",
    "            image = image_train_transform(image)\n",
    "        else:\n",
    "            image = image_test_transform(image)\n",
    "        label = torch.tensor([center_x, center_y, width, height])\n",
    "\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_list)\n",
    "\n",
    "train_datasets = custom_dataset(train_img_list, is_train=True)\n",
    "val_datasets = custom_dataset(val_img_list, is_train=False)\n",
    "test_datasets = custom_dataset(test_img_list, is_train=False)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_datasets, batch_size=8, shuffle=True, num_workers=2)\n",
    "valloader = torch.utils.data.DataLoader(val_datasets, batch_size=8, shuffle=False, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(test_datasets, batch_size=1, shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "############################################################################\n",
    "#\n",
    "#                   Sample visualization\n",
    "#\n",
    "############################################################################\n",
    "\n",
    "sample_image, sample_label = next(iter(trainloader))\n",
    "\n",
    "sample_image = sample_image[0]\n",
    "sample_label = sample_label[0]\n",
    "\n",
    "sample_image = image_inverse_transform(sample_image)\n",
    "\n",
    "sample_cx = sample_label[0] * W\n",
    "sample_cy = sample_label[1]* H\n",
    "sample_w = sample_label[2]* W\n",
    "sample_h = sample_label[3] * H\n",
    "\n",
    "# calculate the left-top & right-down coordinates from the box info( x, y, w, h)\n",
    "sample_x1 = sample_cx - torch.div(sample_w, 2, rounding_mode='floor')\n",
    "sample_y1 = sample_cy - torch.div(sample_h, 2, rounding_mode='floor')\n",
    "sample_x2 = sample_cx + torch.div(sample_w, 2, rounding_mode='floor')\n",
    "sample_y2 = sample_cy + torch.div(sample_h, 2, rounding_mode='floor')\n",
    "\n",
    "sample_image = sample_image.numpy().transpose(1,2,0).copy() * 255\n",
    "print('               ( X,   Y)')\n",
    "print('Top Left     : (%3d,%3d)'%(sample_x1,sample_y1))\n",
    "print('Bottom Right : (%3d,%3d)'%(sample_x2,sample_y2))\n",
    "\n",
    "sample_image = cv2.rectangle(sample_image, (int(sample_x1), int(sample_y1)), (int(sample_x2),int(sample_y2)), (255,0,0), (1)) # draw blue rectangle on the image\n",
    "# sample_image = cv2.UMat.get(sample_image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tiRCukpJ0WgZ"
   },
   "source": [
    "## **You have to make your own network.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0FXzAC2vNj-V",
    "outputId": "f35c7652-2a76-426b-f929-d649a700b069"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Network!\n",
      "\n",
      "Epoch 0\n",
      "\n",
      "Train:\n",
      "[  1/210] | Loss: 0.09994\n",
      "[ 71/210] | Loss: 0.02351\n",
      "[141/210] | Loss: 0.01975\n",
      "[210/210] | Loss: 0.01794\n",
      "\n",
      "Validation:\n",
      "[  1/ 24] | Loss: 0.00272\n",
      "[  9/ 24] | Loss: 0.00386\n",
      "[ 17/ 24] | Loss: 0.00434\n",
      "[ 24/ 24] | Loss: 0.00446\n",
      "\n",
      "Epoch 1\n",
      "\n",
      "Train:\n",
      "[  1/210] | Loss: 0.01456\n",
      "[ 71/210] | Loss: 0.01373\n",
      "[141/210] | Loss: 0.01357\n",
      "[210/210] | Loss: 0.01298\n",
      "\n",
      "Validation:\n",
      "[  1/ 24] | Loss: 0.00192\n",
      "[  9/ 24] | Loss: 0.00245\n",
      "[ 17/ 24] | Loss: 0.00261\n",
      "[ 24/ 24] | Loss: 0.00272\n",
      "\n",
      "Epoch 2\n",
      "\n",
      "Train:\n",
      "[  1/210] | Loss: 0.01718\n",
      "[ 71/210] | Loss: 0.01227\n",
      "[141/210] | Loss: 0.01247\n",
      "[210/210] | Loss: 0.01221\n",
      "\n",
      "Validation:\n",
      "[  1/ 24] | Loss: 0.00199\n",
      "[  9/ 24] | Loss: 0.00312\n",
      "[ 17/ 24] | Loss: 0.00322\n",
      "[ 24/ 24] | Loss: 0.00333\n",
      "\n",
      "Epoch 3\n",
      "\n",
      "Train:\n",
      "[  1/210] | Loss: 0.01807\n",
      "[ 71/210] | Loss: 0.01183\n",
      "[141/210] | Loss: 0.01120\n",
      "[210/210] | Loss: 0.01078\n",
      "\n",
      "Validation:\n",
      "[  1/ 24] | Loss: 0.00359\n",
      "[  9/ 24] | Loss: 0.00341\n",
      "[ 17/ 24] | Loss: 0.00354\n",
      "[ 24/ 24] | Loss: 0.00361\n",
      "\n",
      "Epoch 4\n",
      "\n",
      "Train:\n",
      "[  1/210] | Loss: 0.00539\n",
      "[ 71/210] | Loss: 0.01133\n",
      "[141/210] | Loss: 0.01093\n",
      "[210/210] | Loss: 0.01082\n",
      "\n",
      "Validation:\n",
      "[  1/ 24] | Loss: 0.00200\n",
      "[  9/ 24] | Loss: 0.00165\n",
      "[ 17/ 24] | Loss: 0.00186\n",
      "[ 24/ 24] | Loss: 0.00179\n",
      "\n",
      "Epoch 5\n",
      "\n",
      "Train:\n",
      "[  1/210] | Loss: 0.00816\n",
      "[ 71/210] | Loss: 0.00994\n",
      "[141/210] | Loss: 0.00975\n",
      "[210/210] | Loss: 0.00985\n",
      "\n",
      "Validation:\n",
      "[  1/ 24] | Loss: 0.00217\n",
      "[  9/ 24] | Loss: 0.00215\n",
      "[ 17/ 24] | Loss: 0.00255\n",
      "[ 24/ 24] | Loss: 0.00247\n",
      "\n",
      "Epoch 6\n",
      "\n",
      "Train:\n",
      "[  1/210] | Loss: 0.00950\n",
      "[ 71/210] | Loss: 0.00941\n",
      "[141/210] | Loss: 0.00949\n",
      "[210/210] | Loss: 0.00929\n",
      "\n",
      "Validation:\n",
      "[  1/ 24] | Loss: 0.00188\n",
      "[  9/ 24] | Loss: 0.00166\n",
      "[ 17/ 24] | Loss: 0.00180\n",
      "[ 24/ 24] | Loss: 0.00178\n",
      "\n",
      "Epoch 7\n",
      "\n",
      "Train:\n",
      "[  1/210] | Loss: 0.00385\n",
      "[ 71/210] | Loss: 0.00887\n",
      "[141/210] | Loss: 0.00925\n",
      "[210/210] | Loss: 0.00905\n",
      "\n",
      "Validation:\n",
      "[  1/ 24] | Loss: 0.00407\n",
      "[  9/ 24] | Loss: 0.00343\n",
      "[ 17/ 24] | Loss: 0.00343\n",
      "[ 24/ 24] | Loss: 0.00353\n",
      "\n",
      "Epoch 8\n",
      "\n",
      "Train:\n",
      "[  1/210] | Loss: 0.00638\n",
      "[ 71/210] | Loss: 0.00812\n",
      "[141/210] | Loss: 0.00855\n",
      "[210/210] | Loss: 0.00856\n",
      "\n",
      "Validation:\n",
      "[  1/ 24] | Loss: 0.00115\n",
      "[  9/ 24] | Loss: 0.00121\n",
      "[ 17/ 24] | Loss: 0.00124\n",
      "[ 24/ 24] | Loss: 0.00126\n",
      "\n",
      "Epoch 9\n",
      "\n",
      "Train:\n",
      "[  1/210] | Loss: 0.01315\n",
      "[ 71/210] | Loss: 0.00828\n",
      "[141/210] | Loss: 0.00831\n",
      "[210/210] | Loss: 0.00834\n",
      "\n",
      "Validation:\n",
      "[  1/ 24] | Loss: 0.00105\n",
      "[  9/ 24] | Loss: 0.00122\n",
      "[ 17/ 24] | Loss: 0.00128\n",
      "[ 24/ 24] | Loss: 0.00129\n",
      "\n",
      "Epoch 10\n",
      "\n",
      "Train:\n",
      "[  1/210] | Loss: 0.00352\n",
      "[ 71/210] | Loss: 0.00858\n",
      "[141/210] | Loss: 0.00856\n",
      "[210/210] | Loss: 0.00828\n",
      "\n",
      "Validation:\n",
      "[  1/ 24] | Loss: 0.00097\n",
      "[  9/ 24] | Loss: 0.00111\n",
      "[ 17/ 24] | Loss: 0.00125\n",
      "[ 24/ 24] | Loss: 0.00126\n",
      "\n",
      "Epoch 11\n",
      "\n",
      "Train:\n",
      "[  1/210] | Loss: 0.00714\n",
      "[ 71/210] | Loss: 0.00758\n",
      "[141/210] | Loss: 0.00750\n",
      "[210/210] | Loss: 0.00765\n",
      "\n",
      "Validation:\n",
      "[  1/ 24] | Loss: 0.00112\n",
      "[  9/ 24] | Loss: 0.00099\n",
      "[ 17/ 24] | Loss: 0.00100\n",
      "[ 24/ 24] | Loss: 0.00106\n",
      "\n",
      "Epoch 12\n",
      "\n",
      "Train:\n",
      "[  1/210] | Loss: 0.00381\n",
      "[ 71/210] | Loss: 0.00689\n",
      "[141/210] | Loss: 0.00727\n",
      "[210/210] | Loss: 0.00725\n",
      "\n",
      "Validation:\n",
      "[  1/ 24] | Loss: 0.00151\n",
      "[  9/ 24] | Loss: 0.00138\n",
      "[ 17/ 24] | Loss: 0.00136\n",
      "[ 24/ 24] | Loss: 0.00146\n",
      "\n",
      "Epoch 13\n",
      "\n",
      "Train:\n",
      "[  1/210] | Loss: 0.00526\n",
      "[ 71/210] | Loss: 0.00693\n",
      "[141/210] | Loss: 0.00772\n",
      "[210/210] | Loss: 0.00741\n",
      "\n",
      "Validation:\n",
      "[  1/ 24] | Loss: 0.00217\n",
      "[  9/ 24] | Loss: 0.00222\n",
      "[ 17/ 24] | Loss: 0.00219\n",
      "[ 24/ 24] | Loss: 0.00220\n",
      "\n",
      "Epoch 14\n",
      "\n",
      "Train:\n",
      "[  1/210] | Loss: 0.00436\n",
      "[ 71/210] | Loss: 0.00718\n",
      "[141/210] | Loss: 0.00734\n",
      "[210/210] | Loss: 0.00739\n",
      "\n",
      "Validation:\n",
      "[  1/ 24] | Loss: 0.00133\n",
      "[  9/ 24] | Loss: 0.00127\n",
      "[ 17/ 24] | Loss: 0.00122\n",
      "[ 24/ 24] | Loss: 0.00127\n",
      "\n",
      "Epoch 15\n",
      "\n",
      "Train:\n",
      "[  1/210] | Loss: 0.01207\n",
      "[ 71/210] | Loss: 0.00739\n",
      "[141/210] | Loss: 0.00699\n",
      "[210/210] | Loss: 0.00678\n",
      "\n",
      "Validation:\n",
      "[  1/ 24] | Loss: 0.00143\n",
      "[  9/ 24] | Loss: 0.00144\n",
      "[ 17/ 24] | Loss: 0.00141\n",
      "[ 24/ 24] | Loss: 0.00144\n",
      "\n",
      "Epoch 16\n",
      "\n",
      "Train:\n",
      "[  1/210] | Loss: 0.00789\n",
      "[ 71/210] | Loss: 0.00698\n",
      "[141/210] | Loss: 0.00684\n",
      "[210/210] | Loss: 0.00679\n",
      "\n",
      "Validation:\n",
      "[  1/ 24] | Loss: 0.00159\n",
      "[  9/ 24] | Loss: 0.00140\n",
      "[ 17/ 24] | Loss: 0.00147\n",
      "[ 24/ 24] | Loss: 0.00148\n",
      "\n",
      "Epoch 17\n",
      "\n",
      "Train:\n",
      "[  1/210] | Loss: 0.00444\n",
      "[ 71/210] | Loss: 0.00650\n",
      "[141/210] | Loss: 0.00667\n",
      "[210/210] | Loss: 0.00668\n",
      "\n",
      "Validation:\n",
      "[  1/ 24] | Loss: 0.00093\n",
      "[  9/ 24] | Loss: 0.00087\n",
      "[ 17/ 24] | Loss: 0.00083\n",
      "[ 24/ 24] | Loss: 0.00088\n",
      "\n",
      "Epoch 18\n",
      "\n",
      "Train:\n",
      "[  1/210] | Loss: 0.01121\n",
      "[ 71/210] | Loss: 0.00657\n",
      "[141/210] | Loss: 0.00664\n",
      "[210/210] | Loss: 0.00669\n",
      "\n",
      "Validation:\n",
      "[  1/ 24] | Loss: 0.00148\n",
      "[  9/ 24] | Loss: 0.00135\n",
      "[ 17/ 24] | Loss: 0.00137\n",
      "[ 24/ 24] | Loss: 0.00139\n",
      "\n",
      "Epoch 19\n",
      "\n",
      "Train:\n",
      "[  1/210] | Loss: 0.00623\n",
      "[ 71/210] | Loss: 0.00688\n",
      "[141/210] | Loss: 0.00658\n",
      "[210/210] | Loss: 0.00670\n",
      "\n",
      "Validation:\n",
      "[  1/ 24] | Loss: 0.00064\n",
      "[  9/ 24] | Loss: 0.00079\n",
      "[ 17/ 24] | Loss: 0.00076\n",
      "[ 24/ 24] | Loss: 0.00076\n",
      "\n",
      "Epoch 20\n",
      "\n",
      "Train:\n",
      "[  1/210] | Loss: 0.00274\n",
      "[ 71/210] | Loss: 0.00622\n",
      "[141/210] | Loss: 0.00624\n",
      "[210/210] | Loss: 0.00610\n",
      "\n",
      "Validation:\n",
      "[  1/ 24] | Loss: 0.00086\n",
      "[  9/ 24] | Loss: 0.00099\n",
      "[ 17/ 24] | Loss: 0.00091\n",
      "[ 24/ 24] | Loss: 0.00094\n",
      "\n",
      "Epoch 21\n",
      "\n",
      "Train:\n",
      "[  1/210] | Loss: 0.00684\n",
      "[ 71/210] | Loss: 0.00593\n",
      "[141/210] | Loss: 0.00586\n",
      "[210/210] | Loss: 0.00591\n",
      "\n",
      "Validation:\n",
      "[  1/ 24] | Loss: 0.00097\n",
      "[  9/ 24] | Loss: 0.00103\n",
      "[ 17/ 24] | Loss: 0.00096\n",
      "[ 24/ 24] | Loss: 0.00096\n",
      "\n",
      "Epoch 22\n",
      "\n",
      "Train:\n",
      "[  1/210] | Loss: 0.00579\n",
      "[ 71/210] | Loss: 0.00622\n",
      "[141/210] | Loss: 0.00652\n",
      "[210/210] | Loss: 0.00629\n",
      "\n",
      "Validation:\n",
      "[  1/ 24] | Loss: 0.00091\n",
      "[  9/ 24] | Loss: 0.00100\n",
      "[ 17/ 24] | Loss: 0.00108\n",
      "[ 24/ 24] | Loss: 0.00118\n",
      "\n",
      "Epoch 23\n",
      "\n",
      "Train:\n",
      "[  1/210] | Loss: 0.00525\n",
      "[ 71/210] | Loss: 0.00581\n",
      "[141/210] | Loss: 0.00596\n",
      "[210/210] | Loss: 0.00599\n",
      "\n",
      "Validation:\n",
      "[  1/ 24] | Loss: 0.00106\n",
      "[  9/ 24] | Loss: 0.00118\n",
      "[ 17/ 24] | Loss: 0.00109\n",
      "[ 24/ 24] | Loss: 0.00111\n",
      "\n",
      "Epoch 24\n",
      "\n",
      "Train:\n",
      "[  1/210] | Loss: 0.00721\n",
      "[ 71/210] | Loss: 0.00608\n",
      "[141/210] | Loss: 0.00586\n",
      "[210/210] | Loss: 0.00585\n",
      "\n",
      "Validation:\n",
      "[  1/ 24] | Loss: 0.00150\n",
      "[  9/ 24] | Loss: 0.00152\n",
      "[ 17/ 24] | Loss: 0.00146\n",
      "[ 24/ 24] | Loss: 0.00149\n",
      "\n",
      "Epoch 25\n",
      "\n",
      "Train:\n",
      "[  1/210] | Loss: 0.00405\n",
      "[ 71/210] | Loss: 0.00564\n",
      "[141/210] | Loss: 0.00564\n",
      "[210/210] | Loss: 0.00571\n",
      "\n",
      "Validation:\n",
      "[  1/ 24] | Loss: 0.00087\n",
      "[  9/ 24] | Loss: 0.00107\n",
      "[ 17/ 24] | Loss: 0.00098\n",
      "[ 24/ 24] | Loss: 0.00101\n",
      "\n",
      "Epoch 26\n",
      "\n",
      "Train:\n",
      "[  1/210] | Loss: 0.00739\n",
      "[ 71/210] | Loss: 0.00556\n",
      "[141/210] | Loss: 0.00594\n",
      "[210/210] | Loss: 0.00586\n",
      "\n",
      "Validation:\n",
      "[  1/ 24] | Loss: 0.00094\n",
      "[  9/ 24] | Loss: 0.00106\n",
      "[ 17/ 24] | Loss: 0.00101\n",
      "[ 24/ 24] | Loss: 0.00104\n",
      "\n",
      "Epoch 27\n",
      "\n",
      "Train:\n",
      "[  1/210] | Loss: 0.00647\n",
      "[ 71/210] | Loss: 0.00562\n",
      "[141/210] | Loss: 0.00562\n",
      "[210/210] | Loss: 0.00559\n",
      "\n",
      "Validation:\n",
      "[  1/ 24] | Loss: 0.00076\n",
      "[  9/ 24] | Loss: 0.00083\n",
      "[ 17/ 24] | Loss: 0.00087\n",
      "[ 24/ 24] | Loss: 0.00088\n",
      "\n",
      "Epoch 28\n",
      "\n",
      "Train:\n",
      "[  1/210] | Loss: 0.00798\n",
      "[ 71/210] | Loss: 0.00580\n",
      "[141/210] | Loss: 0.00562\n",
      "[210/210] | Loss: 0.00561\n",
      "\n",
      "Validation:\n",
      "[  1/ 24] | Loss: 0.00070\n",
      "[  9/ 24] | Loss: 0.00089\n",
      "[ 17/ 24] | Loss: 0.00086\n",
      "[ 24/ 24] | Loss: 0.00089\n",
      "\n",
      "Epoch 29\n",
      "\n",
      "Train:\n",
      "[  1/210] | Loss: 0.00456\n",
      "[ 71/210] | Loss: 0.00555\n",
      "[141/210] | Loss: 0.00555\n",
      "[210/210] | Loss: 0.00541\n",
      "\n",
      "Validation:\n",
      "[  1/ 24] | Loss: 0.00081\n",
      "[  9/ 24] | Loss: 0.00095\n",
      "[ 17/ 24] | Loss: 0.00092\n",
      "[ 24/ 24] | Loss: 0.00095\n",
      "\n",
      "Epoch 30\n",
      "\n",
      "Train:\n",
      "[  1/210] | Loss: 0.00464\n",
      "[ 71/210] | Loss: 0.00522\n",
      "[141/210] | Loss: 0.00526\n",
      "[210/210] | Loss: 0.00523\n",
      "\n",
      "Validation:\n",
      "[  1/ 24] | Loss: 0.00088\n",
      "[  9/ 24] | Loss: 0.00097\n",
      "[ 17/ 24] | Loss: 0.00094\n",
      "[ 24/ 24] | Loss: 0.00098\n",
      "\n",
      "Epoch 31\n",
      "\n",
      "Train:\n",
      "[  1/210] | Loss: 0.00448\n",
      "[ 71/210] | Loss: 0.00544\n",
      "[141/210] | Loss: 0.00538\n",
      "[210/210] | Loss: 0.00541\n",
      "\n",
      "Validation:\n",
      "[  1/ 24] | Loss: 0.00082\n",
      "[  9/ 24] | Loss: 0.00107\n",
      "[ 17/ 24] | Loss: 0.00096\n",
      "[ 24/ 24] | Loss: 0.00101\n",
      "\n",
      "Epoch 32\n",
      "\n",
      "Train:\n",
      "[  1/210] | Loss: 0.00391\n",
      "[ 71/210] | Loss: 0.00481\n",
      "[141/210] | Loss: 0.00492\n",
      "[210/210] | Loss: 0.00498\n",
      "\n",
      "Validation:\n",
      "[  1/ 24] | Loss: 0.00076\n",
      "[  9/ 24] | Loss: 0.00115\n",
      "[ 17/ 24] | Loss: 0.00103\n",
      "[ 24/ 24] | Loss: 0.00107\n",
      "\n",
      "Epoch 33\n",
      "\n",
      "Train:\n",
      "[  1/210] | Loss: 0.01206\n",
      "[ 71/210] | Loss: 0.00534\n",
      "[141/210] | Loss: 0.00505\n",
      "[210/210] | Loss: 0.00502\n",
      "\n",
      "Validation:\n",
      "[  1/ 24] | Loss: 0.00088\n",
      "[  9/ 24] | Loss: 0.00091\n",
      "[ 17/ 24] | Loss: 0.00083\n",
      "[ 24/ 24] | Loss: 0.00089\n",
      "\n",
      "Epoch 34\n",
      "\n",
      "Train:\n",
      "[  1/210] | Loss: 0.00298\n",
      "[ 71/210] | Loss: 0.00495\n",
      "[141/210] | Loss: 0.00478\n",
      "[210/210] | Loss: 0.00468\n",
      "\n",
      "Validation:\n",
      "[  1/ 24] | Loss: 0.00169\n",
      "[  9/ 24] | Loss: 0.00179\n",
      "[ 17/ 24] | Loss: 0.00178\n",
      "[ 24/ 24] | Loss: 0.00188\n",
      "\n",
      "Epoch 35\n",
      "\n",
      "Train:\n",
      "[  1/210] | Loss: 0.00508\n",
      "[ 71/210] | Loss: 0.00479\n",
      "[141/210] | Loss: 0.00485\n",
      "[210/210] | Loss: 0.00502\n",
      "\n",
      "Validation:\n",
      "[  1/ 24] | Loss: 0.00149\n",
      "[  9/ 24] | Loss: 0.00131\n",
      "[ 17/ 24] | Loss: 0.00118\n",
      "[ 24/ 24] | Loss: 0.00123\n",
      "\n",
      "Epoch 36\n",
      "\n",
      "Train:\n",
      "[  1/210] | Loss: 0.00338\n",
      "[ 71/210] | Loss: 0.00522\n",
      "[141/210] | Loss: 0.00485\n",
      "[210/210] | Loss: 0.00482\n",
      "\n",
      "Validation:\n",
      "[  1/ 24] | Loss: 0.00135\n",
      "[  9/ 24] | Loss: 0.00136\n",
      "[ 17/ 24] | Loss: 0.00123\n",
      "[ 24/ 24] | Loss: 0.00131\n",
      "\n",
      "Epoch 37\n",
      "\n",
      "Train:\n",
      "[  1/210] | Loss: 0.00512\n",
      "[ 71/210] | Loss: 0.00529\n",
      "[141/210] | Loss: 0.00501\n",
      "[210/210] | Loss: 0.00482\n",
      "\n",
      "Validation:\n",
      "[  1/ 24] | Loss: 0.00145\n",
      "[  9/ 24] | Loss: 0.00150\n",
      "[ 17/ 24] | Loss: 0.00139\n",
      "[ 24/ 24] | Loss: 0.00151\n",
      "\n",
      "Epoch 38\n",
      "\n",
      "Train:\n",
      "[  1/210] | Loss: 0.00413\n",
      "[ 71/210] | Loss: 0.00477\n",
      "[141/210] | Loss: 0.00474\n",
      "[210/210] | Loss: 0.00477\n",
      "\n",
      "Validation:\n",
      "[  1/ 24] | Loss: 0.00092\n",
      "[  9/ 24] | Loss: 0.00113\n",
      "[ 17/ 24] | Loss: 0.00107\n",
      "[ 24/ 24] | Loss: 0.00112\n",
      "\n",
      "Epoch 39\n",
      "\n",
      "Train:\n",
      "[  1/210] | Loss: 0.00581\n",
      "[ 71/210] | Loss: 0.00442\n",
      "[141/210] | Loss: 0.00464\n",
      "[210/210] | Loss: 0.00465\n",
      "\n",
      "Validation:\n",
      "[  1/ 24] | Loss: 0.00179\n",
      "[  9/ 24] | Loss: 0.00191\n",
      "[ 17/ 24] | Loss: 0.00186\n",
      "[ 24/ 24] | Loss: 0.00191\n",
      "\n",
      "Epoch 40\n",
      "\n",
      "Train:\n",
      "[  1/210] | Loss: 0.00241\n",
      "[ 71/210] | Loss: 0.00488\n",
      "[141/210] | Loss: 0.00467\n",
      "[210/210] | Loss: 0.00471\n",
      "\n",
      "Validation:\n",
      "[  1/ 24] | Loss: 0.00097\n",
      "[  9/ 24] | Loss: 0.00094\n",
      "[ 17/ 24] | Loss: 0.00098\n",
      "[ 24/ 24] | Loss: 0.00098\n",
      "\n",
      "Epoch 41\n",
      "\n",
      "Train:\n",
      "[  1/210] | Loss: 0.00385\n",
      "[ 71/210] | Loss: 0.00453\n",
      "[141/210] | Loss: 0.00453\n",
      "[210/210] | Loss: 0.00463\n",
      "\n",
      "Validation:\n",
      "[  1/ 24] | Loss: 0.00067\n",
      "[  9/ 24] | Loss: 0.00068\n",
      "[ 17/ 24] | Loss: 0.00066\n",
      "[ 24/ 24] | Loss: 0.00068\n",
      "\n",
      "Epoch 42\n",
      "\n",
      "Train:\n",
      "[  1/210] | Loss: 0.00418\n",
      "[ 71/210] | Loss: 0.00457\n",
      "[141/210] | Loss: 0.00463\n",
      "[210/210] | Loss: 0.00463\n",
      "\n",
      "Validation:\n",
      "[  1/ 24] | Loss: 0.00146\n",
      "[  9/ 24] | Loss: 0.00130\n",
      "[ 17/ 24] | Loss: 0.00132\n",
      "[ 24/ 24] | Loss: 0.00139\n",
      "\n",
      "Epoch 43\n",
      "\n",
      "Train:\n",
      "[  1/210] | Loss: 0.00499\n",
      "[ 71/210] | Loss: 0.00417\n",
      "[141/210] | Loss: 0.00453\n",
      "[210/210] | Loss: 0.00439\n",
      "\n",
      "Validation:\n",
      "[  1/ 24] | Loss: 0.00132\n",
      "[  9/ 24] | Loss: 0.00148\n",
      "[ 17/ 24] | Loss: 0.00142\n",
      "[ 24/ 24] | Loss: 0.00149\n",
      "\n",
      "Epoch 44\n",
      "\n",
      "Train:\n",
      "[  1/210] | Loss: 0.00406\n",
      "[ 71/210] | Loss: 0.00456\n",
      "[141/210] | Loss: 0.00452\n",
      "[210/210] | Loss: 0.00436\n",
      "\n",
      "Validation:\n",
      "[  1/ 24] | Loss: 0.00081\n",
      "[  9/ 24] | Loss: 0.00102\n",
      "[ 17/ 24] | Loss: 0.00108\n",
      "[ 24/ 24] | Loss: 0.00114\n",
      "\n",
      "Epoch 45\n",
      "\n",
      "Train:\n",
      "[  1/210] | Loss: 0.00336\n",
      "[ 71/210] | Loss: 0.00469\n",
      "[141/210] | Loss: 0.00464\n",
      "[210/210] | Loss: 0.00459\n",
      "\n",
      "Validation:\n",
      "[  1/ 24] | Loss: 0.00114\n",
      "[  9/ 24] | Loss: 0.00117\n",
      "[ 17/ 24] | Loss: 0.00118\n",
      "[ 24/ 24] | Loss: 0.00122\n",
      "\n",
      "Epoch 46\n",
      "\n",
      "Train:\n",
      "[  1/210] | Loss: 0.00381\n"
     ]
    }
   ],
   "source": [
    "# class FaceNet(nn.Module):\n",
    "#     def __init__(self, H=288, W=384, num_filters=16, padding='same', pool='max', dropout_rate=0.2):\n",
    "#         super(FaceNet, self).__init__()\n",
    "#         ###############################\n",
    "#         if padding == 'valid':\n",
    "#             padding_size = 0\n",
    "#         elif padding == 'same':\n",
    "#             padding_size = 1\n",
    "\n",
    "#         if pool == 'max':\n",
    "#             pool_layer = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "#         elif pool == 'avg':\n",
    "#             pool_layer = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "#         self.layer1 = torch.nn.Sequential(\n",
    "#             torch.nn.Conv2d(3, num_filters, kernel_size=3, stride=1, padding=padding_size),\n",
    "#             nn.BatchNorm2d(num_filters),\n",
    "#             torch.nn.ReLU(),\n",
    "#             pool_layer)                                                                             # (num_filters, H/2, W/2)\n",
    "#         self.layer2 = torch.nn.Sequential(\n",
    "#             torch.nn.Conv2d(num_filters, num_filters*2, kernel_size=3, stride=1, padding=padding_size),\n",
    "#             nn.BatchNorm2d(num_filters*2),\n",
    "#             torch.nn.ReLU(),\n",
    "#             pool_layer)                                                                             # (num_filters*2, H/4, W/4)\n",
    "#         self.layer3 = torch.nn.Sequential(\n",
    "#             torch.nn.Conv2d(num_filters*2, num_filters*4, kernel_size=3, stride=1, padding=padding_size),\n",
    "#             nn.BatchNorm2d(num_filters*4),\n",
    "#             torch.nn.ReLU(),\n",
    "#             pool_layer)                                                                             # (num_filters*4, H/8, W/8)\n",
    "#         self.layer3 = torch.nn.Sequential(\n",
    "#             torch.nn.Conv2d(num_filters*2, num_filters*4, kernel_size=3, stride=1, padding=padding_size),\n",
    "#             nn.BatchNorm2d(num_filters*4),\n",
    "#             torch.nn.ReLU(),\n",
    "#             pool_layer)\n",
    "#         self.feature = nn.Sequential(\n",
    "#             self.layer1,\n",
    "#             self.layer2,\n",
    "#             self.layer3\n",
    "#         )\n",
    "\n",
    "#         self.fc1 = torch.nn.Linear(num_filters*4*(H//8)*(W//8), num_filters*2, bias=True)\n",
    "#         torch.nn.init.xavier_uniform_(self.fc1.weight)\n",
    "#         self.layer4 = torch.nn.Sequential(\n",
    "#             self.fc1,\n",
    "#             torch.nn.ReLU(),\n",
    "#             torch.nn.Dropout(dropout_rate))\n",
    "#         self.fc2 = torch.nn.Linear(num_filters*2, 4, bias=True)\n",
    "#         torch.nn.init.xavier_uniform_(self.fc2.weight)\n",
    "#         self.classifier = nn.Sequential(\n",
    "#             self.layer4,\n",
    "#             self.fc2\n",
    "#         )\n",
    "#         ###############################\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.feature(x)\n",
    "#         x = x.view(x.size(0), -1)\n",
    "#         x = self.classifier(x)\n",
    "#         return x\n",
    "\n",
    "cfg = {\n",
    "    'VGG11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'VGG13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'VGG16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "    'VGG19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
    "    'DEBUG' : [64, 'M']\n",
    "}\n",
    "\n",
    "class FaceNet(nn.Module):\n",
    "    def __init__(self, vgg_name='VGG16', H=288, W=384):\n",
    "        super(FaceNet, self).__init__()\n",
    "        ###############################\n",
    "        self.features = self._make_layers(cfg[vgg_name])\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * H//32 * W//32, 360),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(360, 100),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(100, 4),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.features(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.classifier(out)\n",
    "        return out\n",
    "    def _make_layers(self, cfg):\n",
    "        layers = []\n",
    "        in_channels = 3\n",
    "        for x in cfg:\n",
    "            if x == 'M':\n",
    "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "            else:\n",
    "                layers += [nn.Conv2d(in_channels, x, kernel_size=3, padding=1),\n",
    "                           nn.BatchNorm2d(x),\n",
    "                           nn.ReLU(inplace=True)]\n",
    "                in_channels = x\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "print('Building Network!')\n",
    "net = FaceNet()\n",
    "\n",
    "net = net.to(device)\n",
    "if device == 'cuda':\n",
    "    net = torch.nn.DataParallel(net)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "criterion = nn.SmoothL1Loss()\n",
    "# criterion = nn.MSELoss()\n",
    "# optimizer = optim.SGD(net.parameters(), momentum=0.9, weight_decay=5e-4, lr=1e-4)\n",
    "optimizer = optim.AdamW(net.parameters(), lr=learning_rate)\n",
    "# scheduler = optim.lr_scheduler.LambdaLR(optimizer=optimizer,\n",
    "#                                         lr_lambda=lambda epoch: 0.95 ** epoch)\n",
    "# epochs = 200\n",
    "\n",
    "def train(epoch):\n",
    "    print('\\nTrain:')\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (images, targets) in enumerate(trainloader):\n",
    "        optimizer.zero_grad()\n",
    "        images, targets = images.to(device), targets.to(device)\n",
    "        outputs = net(images)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        if ((batch_idx+1) % (len(trainloader)/3) == 1) or batch_idx+ 1 == len(trainloader):\n",
    "            print('[%3d/%3d] | Loss: %.5f'%(batch_idx+1, len(trainloader), train_loss/(batch_idx+1)))\n",
    "            wandb.log({\"Training loss\": train_loss/(batch_idx+1)})\n",
    "    # print('[%3d/%3d] | Loss: %.5f'%(batch_idx+1, len(trainloader), train_loss/(batch_idx+1)))\n",
    "\n",
    "def val(epoch):\n",
    "    print('\\nValidation:')\n",
    "    net.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (images, labels) in enumerate(valloader):\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = net(images)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            # scheduler.step()\n",
    "\n",
    "            if ((batch_idx+1) % (len(valloader)/3) == 1) or batch_idx+ 1 == len(valloader):\n",
    "                print('[%3d/%3d] | Loss: %.5f'%(batch_idx+1, len(valloader), val_loss/(batch_idx+1)))\n",
    "                wandb.log({\"Validation loss\": val_loss/(batch_idx+1)})\n",
    "        # print('[%3d/%3d] | Loss: %.5f'%(batch_idx+1, len(valloader), val_loss/(batch_idx+1)))\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print('\\nEpoch %d'%(epoch))\n",
    "    train(epoch)\n",
    "    val(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nu4LRLat0bH7"
   },
   "source": [
    "##**Do NOT touch this cell**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_30y5Ekp98S0"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(6, 300)\n",
    "\n",
    "visualize_idx = np.random.randint(len(testloader), size=100)\n",
    "cnt = 0\n",
    "test_loss = 0\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    print('\\nTest:')\n",
    "    net.eval()\n",
    "    for batch_idx, (images, labels) in enumerate(testloader):\n",
    "        optimizer.zero_grad()\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = net(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item()\n",
    "        if batch_idx+1 == len(testloader):\n",
    "            print('[%3d/%3d] | final_MSE: %f'%(batch_idx+1, len(testloader), test_loss/(batch_idx+1)))\n",
    "            print('\\033[31m' + '[GT □]' + '\\033[30m' +' | ' + '\\033[34m' +'[Pred □]' +  '\\033[0m')\n",
    "        if batch_idx in visualize_idx: # visualize for selected images\n",
    "            subplot = fig.add_subplot(2,50, cnt+1)\n",
    "\n",
    "            sample_image = images[0]\n",
    "            sample_outputs = outputs[0]\n",
    "            sample_label = labels[0]\n",
    "\n",
    "            sample_image = image_inverse_transform(sample_image)\n",
    "            sample_image = sample_image.cpu().numpy().transpose(1,2,0) * 255\n",
    "\n",
    "\n",
    "\n",
    "            # Draw for predicted box\n",
    "            sample_cx = sample_outputs[0] * W\n",
    "            sample_cy = sample_outputs[1] * H\n",
    "            sample_w = sample_outputs[2] * W\n",
    "            sample_h = sample_outputs[3] * H\n",
    "\n",
    "            sample_x1 = sample_cx - torch.div(sample_w, 2, rounding_mode='floor')\n",
    "            sample_y1 = sample_cy - torch.div(sample_h, 2, rounding_mode='floor')\n",
    "            sample_x2 = sample_cx + torch.div(sample_w, 2, rounding_mode='floor')\n",
    "            sample_y2 = sample_cy + torch.div(sample_h, 2, rounding_mode='floor')\n",
    "\n",
    "            sample_image = cv2.rectangle(sample_image.copy(), (int(sample_x1), int(sample_y1)), (int(sample_x2),int(sample_y2)), (255, 0, 0), (3))\n",
    "            # sample_image = cv2.UMat.get(sample_image)\n",
    "\n",
    "            # Draw for groundtruth box\n",
    "            sample_cx = sample_label[0] * W\n",
    "            sample_cy = sample_label[1] * H\n",
    "            sample_w = sample_label[2] * W\n",
    "            sample_h = sample_label[3] * H\n",
    "\n",
    "            sample_x1 = sample_cx - torch.div(sample_w, 2, rounding_mode='floor')\n",
    "            sample_y1 = sample_cy - torch.div(sample_h, 2, rounding_mode='floor')\n",
    "            sample_x2 = sample_cx + torch.div(sample_w, 2, rounding_mode='floor')\n",
    "            sample_y2 = sample_cy + torch.div(sample_h, 2, rounding_mode='floor')\n",
    "\n",
    "            sample_image = cv2.rectangle(sample_image.copy(), (int(sample_x1), int(sample_y1)), (int(sample_x2),int(sample_y2)), (0, 0, 255), (3))\n",
    "\n",
    "            subplot.set_xticks([])\n",
    "            subplot.set_yticks([])\n",
    "            subplot.set_title('%f'%loss.item())\n",
    "            subplot.imshow(cv2.cvtColor(sample_image.astype('uint8'), cv2.COLOR_BGR2RGB))\n",
    "            cnt += 1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aYM8psgHrzLY"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
